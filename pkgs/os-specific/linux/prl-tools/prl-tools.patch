diff -puNr prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg.c prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg.c
--- prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg.c
+++ prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg.c
@@ -382,7 +382,7 @@ static int prl_tg_initialize(struct tg_d
 	}
 #endif
 	/* Set DMA ability. Only lower 4G is possible to address */
-	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
+	rc = dma_set_mask(&pdev->dev, DMA_BIT_MASK(64));
 	if (rc) {
 		printk(KERN_ERR "no usable DMA configuration\n");
 		goto err_out;
diff -puNr prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg_call.c prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg_call.c
--- prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg_call.c
+++ prl-tools-build/kmods/prl_tg/Toolgate/Guest/Linux/prl_tg/prltg_call.c
@@ -76,7 +76,7 @@ static int tg_req_map_internal(struct TG
 		uple->p[i] = vmalloc_to_page(mem);
 		page_cache_get(uple->p[i]);
 
-		dst->RequestPages[i] = pci_map_page(pdev, uple->p[i], 0, PAGE_SIZE, DMA_BIDIRECTIONAL) >> PAGE_SHIFT;
+		dst->RequestPages[i] = dma_map_page(&pdev->dev, uple->p[i], 0, PAGE_SIZE, DMA_BIDIRECTIONAL) >> PAGE_SHIFT;
 		if (!dst->RequestPages[i]) {
 			page_cache_release(uple->p[i]);
 			goto err;
@@ -88,7 +88,7 @@ static int tg_req_map_internal(struct TG
 
 err:
 	for (i = 0; i < uple->count; i++) {
-		pci_unmap_page(pdev, dst->RequestPages[i] << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_unmap_page(&pdev->dev, dst->RequestPages[i] << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
 		page_cache_release(uple->p[i]);
 	}
 	kfree(uple);
@@ -129,7 +129,7 @@ static TG_PAGED_BUFFER *tg_req_map_user_
 	pfn = (u64 *)dbuf - 1;
 
 	for (; npages > 0; npages--, mapped++) {
-		dma_addr_t addr = pci_map_page(pdev, uple->p[npages-1], 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_addr_t addr = dma_map_page(&pdev->dev, uple->p[npages-1], 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
 
 		if (!addr) {
 			DPRINTK("[3] %d < %d	\n", got, npages);
@@ -144,7 +144,7 @@ static TG_PAGED_BUFFER *tg_req_map_user_
 
 err_unmap:
 	for (i = 0; i < mapped; i++, pfn++)
-		pci_unmap_page(pdev, *pfn << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_unmap_page(&pdev->dev, *pfn << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
 
 err_put:
 	for(i = 0; i < got; i++)
@@ -176,7 +176,7 @@ static TG_PAGED_BUFFER *tg_req_map_kerne
 			goto err;
 		}
 
-		addr = pci_map_page(pdev, page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		addr = dma_map_page(&pdev->dev, page, 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
 		if (!addr) {
 			DPRINTK("[2] va:%p can't map\n", buffer);
 			goto err;
@@ -189,7 +189,7 @@ static TG_PAGED_BUFFER *tg_req_map_kerne
 
 err:
 	for (; i > 0; i--, pfn--)
-		pci_unmap_page(pdev, *pfn << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_unmap_page(&pdev->dev, *pfn << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
 
 	return ERR_PTR(-ENOMEM);
 }
@@ -203,7 +203,7 @@ static inline int tg_req_unmap_internal(
 			dst->RequestSize + ~PAGE_MASK) >> PAGE_SHIFT;
 
 	for (i = 0; i < count; i++)
-		pci_unmap_page(req->dev->pci_dev, dst->RequestPages[i] << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_unmap_page(&req->dev->pci_dev->dev, dst->RequestPages[i] << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
 
 	return count;
 }
@@ -264,7 +264,7 @@ static void tg_req_unmap_pages(struct TG
 
 		pfn = (u64 *)(dbuf + 1);
 		for (; npages > 0; npages--, pfn++)
-			pci_unmap_page(pdev, (*pfn) << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
+			dma_unmap_page(&pdev->dev, (*pfn) << PAGE_SHIFT, PAGE_SIZE, DMA_BIDIRECTIONAL);
 
 		dbuf = (TG_PAGED_BUFFER *)pfn;
 	}
@@ -374,7 +374,7 @@ static int tg_req_submit(struct TG_PENDI
 	 * also no any offset inside page needed.
 	 */
 	req->pg = vmalloc_to_page(dst);
-	req->phys = pci_map_page(dev->pci_dev, vmalloc_to_page(dst), 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
+	req->phys = dma_map_page(&dev->pci_dev->dev, vmalloc_to_page(dst), 0, PAGE_SIZE, DMA_BIDIRECTIONAL);
 	if (!req->phys) {
 		DPRINTK("Can not allocate memory for DMA mapping\n");
 		goto out;
@@ -405,7 +405,7 @@ static int tg_req_submit(struct TG_PENDI
 out:
 	if (ret != TG_STATUS_PENDING) {
 		page_cache_release(req->pg);
-		pci_unmap_page(dev->pci_dev, req->phys, PAGE_SIZE, DMA_BIDIRECTIONAL);
+		dma_unmap_page(&dev->pci_dev->dev, req->phys, PAGE_SIZE, DMA_BIDIRECTIONAL);
 	}
 
 	DPRINTK("EXIT\n");
@@ -460,7 +460,7 @@ out_wait:
 	wait_for_completion(&req->waiting);
 out:
 	page_cache_release(req->pg);
-	pci_unmap_page(dev->pci_dev, req->phys, PAGE_SIZE, DMA_BIDIRECTIONAL);
+	dma_unmap_page(&dev->pci_dev->dev, req->phys, PAGE_SIZE, DMA_BIDIRECTIONAL);
 	DPRINTK("EXIT\n");
 	return ret;
 }
diff -puNr prl-tools-build/kmods/prl_fs/SharedFolders/Guest/Linux/prl_fs/inode.c prl-tools-build/kmods/prl_fs/SharedFolders/Guest/Linux/prl_fs/inode.c
--- prl-tools-build/kmods/prl_fs/SharedFolders/Guest/Linux/prl_fs/inode.c
+++ prl-tools-build/kmods/prl_fs/SharedFolders/Guest/Linux/prl_fs/inode.c
@@ -16,6 +16,7 @@
 #include <linux/pagemap.h>
 #include <linux/namei.h>
 #include <linux/cred.h>
+#include <linux/writeback.h>
 
 #if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 40)) && \
     (LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0))
@@ -57,7 +58,7 @@ unsigned long *prlfs_dfl( struct dentry
 }
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 9, 0)
-#define prl_uaccess_kernel() uaccess_kernel()
+#define prl_uaccess_kernel() (false)
 #else
 #define prl_uaccess_kernel() segment_eq(get_fs(), KERNEL_DS)
 #endif
@@ -954,7 +955,7 @@ static const struct address_space_operat
 	.writepage		= prlfs_writepage,
 	.write_begin    = simple_write_begin,
 	.write_end      = prlfs_write_end,
-	.set_page_dirty = __set_page_dirty_nobuffers,
+	.dirty_folio    = filemap_dirty_folio,
 };
 
 

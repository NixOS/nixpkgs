{ config, lib, options, pkgs, ... }:

with lib;

let
  settingsFormat = let
    listSep = ",";
    baseTypes = with types; [ bool int float str ];
    entryType = with types; oneOf ([ (listOf (oneOf baseTypes)) ] ++ baseTypes);
    settingsType = with types; oneOf [ (attrsOf (attrsOf entryType)) entryType ];

    entryToString = key: val:
        if isAttrs val then concatStringsSep "\n" (mapAttrsToList (subKey: subVal: "${key}=${subKey} ${valueToString subVal}") val)
        else "${key}=${valueToString val}";

    valueToString = val:
        if isList val then concatStringsSep listSep (map (x: valueToString x) val)
        else if isBool val then (if val then "YES" else "NO")
        else if isAttrs val then concatStringsSep " " (mapAttrsToList (k: v: "${k}=${valueToString v}") val)
        else toString val;

    in {
      type = types.attrsOf settingsType // {
        description = "Format of slurm config files.";
      };

      generate = name: value: extraText:
        pkgs.writeTextDir name (( concatStringsSep "\n" (
          mapAttrsToList (key: val: entryToString key val ) value )) + "\n"
            + (optionalString (extraText != null) extraText));
   };

  cfg = config.services.slurm;
  opt = options.services.slurm;
  # configuration file can be generated by http://slurm.schedmd.com/configurator.html

  defaultUser = "slurm";

  configFile = settingsFormat.generate "slurm.conf" cfg.settings cfg.extraConfig;

  plugStackConfig = pkgs.writeTextDir "plugstack.conf"
    ''
      ${optionalString cfg.enableSrunX11 "optional ${pkgs.slurm-spank-x11}/lib/x11.so"}
      ${cfg.extraPlugstackConfig}
    '';

  cgroupConf = settingsFormat.generate "cgroup.conf" cfg.settingsCgroup null;

  slurmdbdConf = settingsFormat.generate "slurmdbd.conf" cfg.dbdserver.settings null;

  # slurm expects some additional config files to be
  # in the same directory as slurm.conf
  etcSlurm = pkgs.symlinkJoin {
    name = "etc-slurm";
    paths = [ configFile cgroupConf plugStackConfig ] ++ cfg.extraConfigPaths;
  };

in {
  ###### interface

  meta.maintainers = [ maintainers.markuskowa ];

  options = {

    services.slurm = {

      server = {
        enable = mkOption {
          type = types.bool;
          default = false;
          description = lib.mdDoc ''
            Whether to enable the slurm control daemon.
            Note that the standard authentication method is "munge".
            The "munge" service needs to be provided with a password file in order for
            slurm to work properly (see `services.munge.password`).
          '';
        };
      };

      settings = mkOption {
        type = settingsFormat.type;

        description = mdDoc ''
          Contents of `slurm.conf`.
          An interactive configuration generator can be found [here](http://slurm.schedmd.com/configurator.html).
        '';

        example = literalExpression ''
          settings = {
            SlurmctldHost = "control";
            nodeName = {
              "node[1-2]" = {
                CPUs = 4;
                State = "UNKNOWN";
              };
              "node[3-4]" = {
                CPUs = 48;
                State = "UNKNOWN";
              };
            };
            partitionName = {
              debug = {
                Nodes = "node[1-2]";
                Default = true;
                MaxTime = "INFINITE";
                State = "UP";
              };
              big = {
                Nodes = "node[3-4]";
                State = "UP";
              };
            };
          };
        '';
      };

      extraConfig = mkOption {
        default = null;
        type = with types; nullOr lines;
        description = lib.mdDoc ''
          Extra configuration options that will be added verbatim at
          the end of the slurm configuration file.
        '';
      };

      dbdserver = {
        enable = mkEnableOption (lib.mdDoc "SlurmDBD service");

        storagePassFile = mkOption {
          type = with types; nullOr str;
          default = null;
          description = lib.mdDoc ''
            Path to file with database password. The content of this will be used to
            create the password for the `StoragePass` option.
          '';
        };

        settings = mkOption {
          type = settingsFormat.type;
          description = mdDoc "Contents of `slurmdbd.conf`. See also {manpage}`slurmdbd.conf(8)`.";
        };
      };

      client = {
        enable = mkEnableOption (lib.mdDoc "slurm client daemon");
      };

      enableStools = mkOption {
        type = types.bool;
        default = false;
        description = lib.mdDoc ''
          Whether to provide a slurm.conf file.
          Enable this option if you do not run a slurm daemon on this host
          (i.e. {option}`server.enable` and {option}`client.enable` are `false`)
          but you still want to run slurm commands from this host.
        '';
      };

      package = mkOption {
        type = types.package;
        default = pkgs.slurm.override { enableX11 = ! cfg.enableSrunX11; };
        defaultText = literalMD "pkgs.slurm";
        example = literalMD "pkgs.slurm";
        description = mdDoc "The package to use for slurm binaries.";
      };

      enableSrunX11 = mkOption {
        default = false;
        type = types.bool;
        description = lib.mdDoc ''
          If enabled srun will accept the option "--x11" to allow for X11 forwarding
          from within an interactive session or a batch job. This activates the
          slurm-spank-x11 module. Note that this option also enables
          {option}`services.openssh.forwardX11` on the client.

          This option requires slurm to be compiled without native X11 support.
          The default behavior is to re-compile the slurm package with native X11
          support disabled if this option is set to true.

          To use the native X11 support add `PrologFlags=X11` in {option}`extraConfig`.
          Note that this method will only work RSA SSH host keys.
        '';
      };

      user = mkOption {
        type = types.str;
        default = defaultUser;
        description = lib.mdDoc ''
          Set this option when you want to run the slurmctld daemon
          as something else than the default slurm user "slurm".
          Note that the UID of this user needs to be the same
          on all nodes.
        '';
      };

      extraPlugstackConfig = mkOption {
        default = "";
        type = types.lines;
        description = lib.mdDoc ''
          Extra configuration that will be added to the end of `plugstack.conf`.
        '';
      };

      settingsCgroup = mkOption {
        type = settingsFormat.type;
        default = {};
        description = mdDoc "Contents of `cgroup.conf`.";
      };

      extraConfigPaths = mkOption {
        type = with types; listOf path;
        default = [];
        description = lib.mdDoc ''
          Slurm expects config files for plugins in the same path
          as `slurm.conf`. Add extra nix store
          paths that should be merged into same directory as
          `slurm.conf`.
        '';
      };

      etcSlurm = mkOption {
        type = types.path;
        internal = true;
        readOnly = true;
        default = etcSlurm;
        defaultText = literalMD ''
          Directory created from generated config files and
          `config.${opt.extraConfigPaths}`.
        '';
        description = lib.mdDoc ''
          Path to directory with slurm config files. This option is set by default from the
          Slurm module and is meant to make the Slurm config file available to other modules.
        '';
      };

    };

  };

  imports = let
    removeMessage = "This option has been removed. Please have a look at the 23.05 release notes.";
    in [
    (mkRemovedOptionModule [ "services" "slurm" "nodeName" ] ''
      ${removedMessage}
      The nodes are now defined in services.slurm.settings.
    '')
    (mkRemovedOptionModule [ "services" "slurm" "partitionName" ] ''
      ${removedMessage}
      The partitions are now defined in services.slurm.settings.
    '')
    (mkRemovedOptionModule [ "services" "slurm" "extraCgroupConfig" ] ''
      ${removedMessage}
      The configuration for cgroup.conf is now defined in services.slurm.settingsCgroup.
    '')
    (mkRemovedOptionModule [ "services" "slurm" "dbdserver" "extraConfig" ] ''
      ${removedMessage}
      The configuration for dbdserver.conf is now defined in services.slurm.dbdserver.settings.
    '')
    (mkRemovedOptionModule [ "services" "slurm" "controlAddr" ] ''
     This option is deprecated. See slurm.conf manual.
    '')
    (mkRenamedOptionModule [ "services" "slurm" "stateSaveLocation" ] [ "services" "slurm" "settings" "StateSaveLocation" ] )
    (mkRenamedOptionModule [ "services" "slurm" "procTrackType" ] [ "services" "slurm" "settings" "ProcTrackType" ] )
    (mkRenamedOptionModule [ "services" "slurm" "controlMachine" ] [ "services" "slurm" "settings" "SlurmctldHost" ] )
    (mkRenamedOptionModule [ "services" "slurm" "clusterName" ] [ "services" "slurm" "settings" "ClusterName" ] )
  ];

  ###### implementation

  config = let
    wrappedSlurm = pkgs.stdenv.mkDerivation {
      name = "wrappedSlurm";

      builder = pkgs.writeText "builder.sh" ''
        source $stdenv/setup
        mkdir -p $out/bin
        find  ${getBin cfg.package}/bin -type f -executable | while read EXE
        do
          exename="$(basename $EXE)"
          wrappername="$out/bin/$exename"
          cat > "$wrappername" <<EOT
        #!/bin/sh
        if [ -z "$SLURM_CONF" ]
        then
          SLURM_CONF="${cfg.etcSlurm}/slurm.conf" "$EXE" "\$@"
        else
          "$EXE" "\$0"
        fi
        EOT
          chmod +x "$wrappername"
        done
        mkdir -p $out/share
        ln -s ${getMan cfg.package}/share/man $out/share/man
      '';
    };

  in mkIf ( cfg.enableStools ||
           cfg.client.enable ||
           cfg.server.enable ||
           cfg.dbdserver.enable ) {

    assertions = [ {
      assertion = ( cfg.enableStools || cfg.client.enable || cfg.server.enable ) ->
        ( cfg.settings ? ControlMachine || cfg.settings ? SlurmctldHost);
      message = ''
        Neither services.slurm.settings.ControlMachine nor services.slurm.settings.SlurmctldHost is set,
        but Slurm services are requested in the configuation.
        Please set services.slurm.settings.SlurmctldHost to the hostname running slurmcltd.
      '';
    }];

    warnings = optional (cfg.extraConfig != null) ''
      services.slurm.extraConfig is deprecated and will be removed in NixOS 23.11.
      Please have a look at the 23.05 release notes.
    '' ;

    environment = {
      systemPackages = [ wrappedSlurm ];
    };

    services.slurm.settings = {
      ClusterName = mkDefault "default";
      StateSaveLocation = mkDefault "/var/spool/slurmctld";
      SlurmdSpoolDir = mkDefault "/var/spool/slurmd";
      PlugStackConfig = mkDefault "${plugStackConfig}/plugstack.conf";
      SlurmUser = mkDefault cfg.user;
      ProctrackType = mkDefault "proctrack/linuxproc";
    };

    services.munge.enable = mkDefault true;

    # use a static uid as default to ensure it is the same on all nodes
    users.users.slurm = mkIf (cfg.user == defaultUser) {
      name = defaultUser;
      group = "slurm";
      uid = config.ids.uids.slurm;
    };

    users.groups.slurm.gid = mkIf (cfg.user == defaultUser) config.ids.uids.slurm;

    systemd.services.slurmd = mkIf cfg.client.enable {
      path = with pkgs; [ coreutils ]
        ++ lib.optional cfg.enableSrunX11 slurm-spank-x11;

      wantedBy = [ "multi-user.target" ];
      after = [
        "systemd-tmpfiles-clean.service"
        "munge.service"
        "network-online.target"
        "remote-fs.target"
      ];
      wants = [ "network-online.target" ];

      serviceConfig = {
        Type = "forking";
        KillMode = "process";
        ExecStart = "${wrappedSlurm}/bin/slurmd";
        PIDFile = "/run/slurmd.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
        LimitMEMLOCK = "infinity";
        Delegate="Yes";
      };
    };

    systemd.tmpfiles.rules = optional cfg.client.enable
      "d ${cfg.settings.SlurmdSpoolDir} 755 root root -"
       ++ optional cfg.server.enable
      "d ${cfg.settings.StateSaveLocation} 700 ${cfg.user} root -";

    services.openssh.forwardX11 = mkIf cfg.client.enable (mkDefault true);

    systemd.services.slurmctld = mkIf cfg.server.enable {
      path = with pkgs; [ munge coreutils ]
        ++ lib.optional cfg.enableSrunX11 slurm-spank-x11;

      wantedBy = [ "multi-user.target" ];
      after = [ "network.target" "munged.service" ];
      requires = [ "munged.service" ];

      serviceConfig = {
        Type = "forking";
        ExecStart = "${wrappedSlurm}/bin/slurmctld";
        PIDFile = "/run/slurmctld.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
      };
    };

    services.slurm.dbdserver.settings = {
      DbdHost = mkDefault config.networking.hostName;
      SlurmUser = mkDefault cfg.user;
      StorageType = mkDefault "accounting_storage/mysql";
      StorageUser = mkDefault "slurm";
    };

    systemd.services.slurmdbd = let
      # slurm strips the last component off the path
      configPath = "$RUNTIME_DIRECTORY/slurmdbd.conf";
    in mkIf cfg.dbdserver.enable {
      path = with pkgs; [ munge coreutils ];

      wantedBy = [ "multi-user.target" ];
      after = [ "network.target" "munged.service" "mysql.service" ];
      requires = [ "munged.service" "mysql.service" ];

      preStart = ''
        install -m 600 -o ${cfg.dbdserver.settings.SlurmUser} \
          -T ${slurmdbdConf}/slurmdbd.conf ${configPath}

        ${optionalString (cfg.dbdserver.storagePassFile != null) ''
          echo "StoragePass=$(cat ${cfg.dbdserver.storagePassFile})" \
            >> ${configPath}
        ''}
      '';

      script = ''
        export SLURM_CONF=${configPath}
        exec ${cfg.package}/bin/slurmdbd -D
      '';

      serviceConfig = {
        RuntimeDirectory = "slurmdbd";
        Type = "simple";
        PIDFile = "/run/slurmdbd.pid";
        ExecReload = "${pkgs.coreutils}/bin/kill -HUP $MAINPID";
      };
    };
  };
}

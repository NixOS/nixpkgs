commit 425b33877c819dd88f3692aae37452c767371f6b
Author: Simon Gardling <titaniumtown@proton.me>
Date:   Thu Sep 19 10:00:39 2024 -0400

    use locally downloaded embeddings

diff --git a/gpt4all-chat/CMakeLists.txt b/gpt4all-chat/CMakeLists.txt
index 900307ae..802fc31a 100644
--- a//CMakeLists.txt
+++ b/CMakeLists.txt
@@ -120,6 +120,7 @@ elseif (APPLE)
 endif()
 
 # Embedding model
+#[[
 set(LOCAL_EMBEDDING_MODEL "nomic-embed-text-v1.5.f16.gguf")
 set(LOCAL_EMBEDDING_MODEL_MD5 "a5401e7f7e46ed9fcaed5b60a281d547")
 set(LOCAL_EMBEDDING_MODEL_PATH "${CMAKE_BINARY_DIR}/resources/${LOCAL_EMBEDDING_MODEL}")
@@ -134,6 +135,7 @@ message(STATUS "Embedding model downloaded to ${LOCAL_EMBEDDING_MODEL_PATH}")
 if (APPLE)
     list(APPEND CHAT_EXE_RESOURCES "${LOCAL_EMBEDDING_MODEL_PATH}")
 endif()
+]]
 
 set(QAPPLICATION_CLASS QGuiApplication)
 add_subdirectory(deps/SingleApplication)
@@ -348,11 +350,13 @@ if (LLMODEL_CUDA)
     endif()
 endif()
 
+#[[
 if (NOT APPLE)
     install(FILES "${LOCAL_EMBEDDING_MODEL_PATH}"
             DESTINATION resources
             COMPONENT ${COMPONENT_NAME_MAIN})
 endif()
+]]
 
 set(CPACK_GENERATOR "IFW")
 set(CPACK_VERBATIM_VARIABLES YES)
diff --git a/gpt4all-chat/src/embllm.cpp b/gpt4all-chat/src/embllm.cpp
index 81b1e9e1..e3266cc7 100644
--- a/src/embllm.cpp
+++ b/src/embllm.cpp
@@ -84,7 +84,7 @@ bool EmbeddingLLMWorker::loadModel()
 
     QString filePath = embPathFmt.arg(QCoreApplication::applicationDirPath(), LOCAL_EMBEDDING_MODEL);
     if (!QFileInfo::exists(filePath)) {
-        qWarning() << "embllm WARNING: Local embedding model not found";
+        qWarning() << "embllm WARNING: Local embedding model not found: " << filePath;
         return false;
     }
 
